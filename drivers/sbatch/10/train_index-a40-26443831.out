Thu Nov 28 05:18:25 2024       
+-----------------------------------------------------------------------------------------+
| NVIDIA-SMI 550.127.05             Driver Version: 550.127.05     CUDA Version: 12.4     |
|-----------------------------------------+------------------------+----------------------+
| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |
| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |
|                                         |                        |               MIG M. |
|=========================================+========================+======================|
|   0  NVIDIA A40                     On  |   00000000:17:00.0 Off |                    0 |
|  0%   31C    P8             30W /  300W |       1MiB /  46068MiB |      0%      Default |
|                                         |                        |                  N/A |
+-----------------------------------------+------------------------+----------------------+
|   1  NVIDIA A40                     On  |   00000000:65:00.0 Off |                    0 |
|  0%   33C    P8             32W /  300W |       1MiB /  46068MiB |      0%      Default |
|                                         |                        |                  N/A |
+-----------------------------------------+------------------------+----------------------+
|   2  NVIDIA A40                     On  |   00000000:CA:00.0 Off |                    0 |
|  0%   32C    P8             30W /  300W |       1MiB /  46068MiB |      0%      Default |
|                                         |                        |                  N/A |
+-----------------------------------------+------------------------+----------------------+
|   3  NVIDIA A40                     On  |   00000000:E3:00.0 Off |                    0 |
|  0%   31C    P8             24W /  300W |       1MiB /  46068MiB |      0%      Default |
|                                         |                        |                  N/A |
+-----------------------------------------+------------------------+----------------------+
                                                                                         
+-----------------------------------------------------------------------------------------+
| Processes:                                                                              |
|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |
|        ID   ID                                                               Usage      |
|=========================================================================================|
|  No running processes found                                                             |
+-----------------------------------------------------------------------------------------+
sbatch_train_index-a40_subset_10_bottom_neg_only.sh
Loading conda
python -m torch.distributed.launch --nproc_per_node=4 ../drivers/run_ann.py --model_type rdot_nll --model_name_or_path /home/hojaeson_umass_edu/hojae_workspace/project/ance/warmup/checkpoint-150000 --task_name MSMarco --triplet --data_dir /home/hojaeson_umass_edu/hojae_workspace/vector_database/ANCE/data/10/preprocessed_data --ann_dir /home/hojaeson_umass_edu/hojae_workspace/vector_database/ANCE/data/10/ann_data_4_bottom_neg_only --max_seq_length 512 --per_gpu_train_batch_size=16 --gradient_accumulation_steps 2 --learning_rate 1e-6 --output_dir /home/hojaeson_umass_edu/hojae_workspace/vector_database/ANCE/data/10/checkpoints_4_bottom_neg_only --warmup_steps 5000 --logging_steps 100 --save_steps 2000 --optimizer lamb --single_warmup
python -m torch.distributed.launch --master_port=29501 --nproc_per_node=4 ../drivers/run_ann_data_gen.py --training_dir /home/hojaeson_umass_edu/hojae_workspace/project/ance/data/10/checkpoints_4_bottom_neg_only --init_model_dir /home/hojaeson_umass_edu/hojae_workspace/project/ance/warmup/checkpoint-150000 --model_type rdot_nll --output_dir /home/hojaeson_umass_edu/hojae_workspace/project/ance/data/10/ann_data_4_bottom_neg_only --cache_dir /home/hojaeson_umass_edu/hojae_workspace/project/ance/data/10/ann_data_4_bottom_neg_onlycache/ --data_dir /home/hojaeson_umass_edu/hojae_workspace/vector_database/ANCE/data/10/preprocessed_data --max_seq_length 512 --per_gpu_eval_batch_size 256 --topk_training 200 --negative_sample 20 --ann_chunk_factor 20 --bottom_neg true --bottom_only true
/home/hojaeson_umass_edu/hojae_workspace/miniconda3/envs/ance/lib/python3.8/site-packages/torch/distributed/launch.py:178: FutureWarning: The module torch.distributed.launch is deprecated
and will be removed in future. Use torchrun.
Note that --use_env is set by default in torchrun.
If your script expects `--local_rank` argument to be set, please
change it to read from `os.environ['LOCAL_RANK']` instead. See 
https://pytorch.org/docs/stable/distributed.html#launch-utility for 
further instructions

  warnings.warn(
WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
/home/hojaeson_umass_edu/hojae_workspace/miniconda3/envs/ance/lib/python3.8/site-packages/torch/distributed/launch.py:178: FutureWarning: The module torch.distributed.launch is deprecated
and will be removed in future. Use torchrun.
Note that --use_env is set by default in torchrun.
If your script expects `--local_rank` argument to be set, please
change it to read from `os.environ['LOCAL_RANK']` instead. See 
https://pytorch.org/docs/stable/distributed.html#launch-utility for 
further instructions

  warnings.warn(
WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
11/28/2024 05:18:53 - WARNING - __main__ -   Process rank: 3, device: cuda:3, n_gpu: 1, distributed training: True
Process rank: 3, device: cuda:3, n_gpu: 1, distributed training: True
Process rank: 2, device: cuda:2, n_gpu: 1, distributed training: True
11/28/2024 05:18:53 - WARNING - __main__ -   Process rank: 2, device: cuda:2, n_gpu: 1, distributed training: True
11/28/2024 05:18:53 - WARNING - __main__ -   Process rank: 0, device: cuda:0, n_gpu: 1, distributed training: True, 16-bits training: False
Process rank: 0, device: cuda:0, n_gpu: 1, distributed training: True
11/28/2024 05:18:53 - WARNING - __main__ -   Process rank: 0, device: cuda:0, n_gpu: 1, distributed training: True
11/28/2024 05:18:53 - WARNING - __main__ -   Process rank: 3, device: cuda:3, n_gpu: 1, distributed training: True, 16-bits training: False
starting output number 0
11/28/2024 05:18:53 - INFO - __main__ -   starting output number 0
Loading query_2_pos_docid
11/28/2024 05:18:53 - INFO - __main__ -   Loading query_2_pos_docid
11/28/2024 05:18:53 - WARNING - __main__ -   Process rank: 2, device: cuda:2, n_gpu: 1, distributed training: True, 16-bits training: False
11/28/2024 05:18:53 - INFO - transformers.configuration_utils -   loading configuration file /home/hojaeson_umass_edu/hojae_workspace/project/ance/warmup/checkpoint-150000/config.json
11/28/2024 05:18:53 - INFO - transformers.configuration_utils -   Model config {
  "architectures": [
    "RobertaForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "bos_token_id": 0,
  "eos_token_id": 2,
  "finetuning_task": "msmarco",
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1"
  },
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "is_decoder": false,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1
  },
  "layer_norm_eps": 1e-05,
  "max_position_embeddings": 514,
  "model_type": "roberta",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "num_labels": 2,
  "output_attentions": false,
  "output_hidden_states": false,
  "output_past": true,
  "pad_token_id": 1,
  "pruned_heads": {},
  "torchscript": false,
  "type_vocab_size": 1,
  "use_bfloat16": false,
  "vocab_size": 50265
}

11/28/2024 05:18:53 - INFO - transformers.tokenization_utils -   Model name '/home/hojaeson_umass_edu/hojae_workspace/project/ance/warmup/checkpoint-150000' not found in model shortcut name list (roberta-base, roberta-large, roberta-large-mnli, distilroberta-base, roberta-base-openai-detector, roberta-large-openai-detector). Assuming '/home/hojaeson_umass_edu/hojae_workspace/project/ance/warmup/checkpoint-150000' is a path or url to a directory containing tokenizer files.
11/28/2024 05:18:53 - INFO - transformers.tokenization_utils -   loading file /home/hojaeson_umass_edu/hojae_workspace/project/ance/warmup/checkpoint-150000/vocab.json
11/28/2024 05:18:53 - INFO - transformers.tokenization_utils -   loading file /home/hojaeson_umass_edu/hojae_workspace/project/ance/warmup/checkpoint-150000/merges.txt
11/28/2024 05:18:53 - INFO - transformers.tokenization_utils -   loading file /home/hojaeson_umass_edu/hojae_workspace/project/ance/warmup/checkpoint-150000/added_tokens.json
11/28/2024 05:18:53 - INFO - transformers.tokenization_utils -   loading file /home/hojaeson_umass_edu/hojae_workspace/project/ance/warmup/checkpoint-150000/special_tokens_map.json
11/28/2024 05:18:53 - INFO - transformers.tokenization_utils -   loading file /home/hojaeson_umass_edu/hojae_workspace/project/ance/warmup/checkpoint-150000/tokenizer_config.json
Process rank: 1, device: cuda:1, n_gpu: 1, distributed training: True
11/28/2024 05:18:53 - WARNING - __main__ -   Process rank: 1, device: cuda:1, n_gpu: 1, distributed training: True
11/28/2024 05:18:53 - WARNING - __main__ -   Process rank: 1, device: cuda:1, n_gpu: 1, distributed training: True, 16-bits training: False
Loading dev query_2_pos_docid
11/28/2024 05:18:53 - INFO - __main__ -   Loading dev query_2_pos_docid
52887
11/28/2024 05:18:53 - INFO - __main__ -   52887
start generate ann data number 0
11/28/2024 05:18:53 - INFO - __main__ -   start generate ann data number 0
next checkpoint at /home/hojaeson_umass_edu/hojae_workspace/project/ance/warmup/checkpoint-150000
11/28/2024 05:18:53 - INFO - __main__ -   next checkpoint at /home/hojaeson_umass_edu/hojae_workspace/project/ance/warmup/checkpoint-150000
11/28/2024 05:18:53 - INFO - transformers.configuration_utils -   loading configuration file /home/hojaeson_umass_edu/hojae_workspace/project/ance/warmup/checkpoint-150000/config.json
11/28/2024 05:18:53 - INFO - transformers.configuration_utils -   Model config {
  "architectures": [
    "RobertaForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "bos_token_id": 0,
  "eos_token_id": 2,
  "finetuning_task": "MSMarco",
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1"
  },
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "is_decoder": false,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1
  },
  "layer_norm_eps": 1e-05,
  "max_position_embeddings": 514,
  "model_type": "roberta",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "num_labels": 2,
  "output_attentions": false,
  "output_hidden_states": false,
  "output_past": true,
  "pad_token_id": 1,
  "pruned_heads": {},
  "torchscript": false,
  "type_vocab_size": 1,
  "use_bfloat16": false,
  "vocab_size": 50265
}

11/28/2024 05:18:53 - INFO - transformers.tokenization_utils -   Model name '/home/hojaeson_umass_edu/hojae_workspace/project/ance/warmup/checkpoint-150000' not found in model shortcut name list (roberta-base, roberta-large, roberta-large-mnli, distilroberta-base, roberta-base-openai-detector, roberta-large-openai-detector). Assuming '/home/hojaeson_umass_edu/hojae_workspace/project/ance/warmup/checkpoint-150000' is a path or url to a directory containing tokenizer files.
11/28/2024 05:18:53 - INFO - transformers.tokenization_utils -   loading file /home/hojaeson_umass_edu/hojae_workspace/project/ance/warmup/checkpoint-150000/vocab.json
11/28/2024 05:18:53 - INFO - transformers.tokenization_utils -   loading file /home/hojaeson_umass_edu/hojae_workspace/project/ance/warmup/checkpoint-150000/merges.txt
11/28/2024 05:18:53 - INFO - transformers.tokenization_utils -   loading file /home/hojaeson_umass_edu/hojae_workspace/project/ance/warmup/checkpoint-150000/added_tokens.json
11/28/2024 05:18:53 - INFO - transformers.tokenization_utils -   loading file /home/hojaeson_umass_edu/hojae_workspace/project/ance/warmup/checkpoint-150000/special_tokens_map.json
11/28/2024 05:18:53 - INFO - transformers.tokenization_utils -   loading file /home/hojaeson_umass_edu/hojae_workspace/project/ance/warmup/checkpoint-150000/tokenizer_config.json
11/28/2024 05:18:53 - INFO - transformers.modeling_utils -   loading weights file /home/hojaeson_umass_edu/hojae_workspace/project/ance/warmup/checkpoint-150000/pytorch_model.bin
Using mean: False
11/28/2024 05:18:53 - INFO - transformers.modeling_utils -   loading weights file /home/hojaeson_umass_edu/hojae_workspace/project/ance/warmup/checkpoint-150000/pytorch_model.bin
Using mean: False
Using mean: False
Using mean: False
Using mean: False
Inference parameters Namespace(ann_chunk_factor=20, ann_dir='/home/hojaeson_umass_edu/hojae_workspace/vector_database/ANCE/outcome/ann_data', ann_measure_topk_mrr=True, bottom_neg=True, bottom_only=True, cache_dir='/home/hojaeson_umass_edu/hojae_workspace/project/ance/data/10/ann_data_4_bottom_neg_onlycache/', config_name='', data_dir='/home/hojaeson_umass_edu/hojae_workspace/vector_database/ANCE/data/10/preprocessed_data', device=device(type='cuda', index=0), end_output_num=-1, inference=False, init_model_dir='/home/hojaeson_umass_edu/hojae_workspace/project/ance/warmup/checkpoint-150000', last_checkpoint_dir='', limit_total_number=100000, load_gen=False, local_rank=0, max_doc_character=10000, max_query_length=64, max_seq_length=512, model_name_or_path='/home/hojaeson_umass_edu/hojae_workspace/project/ance/warmup/checkpoint-150000', model_type='rdot_nll', n_gpu=1, negative_sample=20, no_cuda=False, only_keep_latest_embedding_file=False, output_dir='/home/hojaeson_umass_edu/hojae_workspace/project/ance/data/10/ann_data_4_bottom_neg_only', per_gpu_eval_batch_size=256, rank=0, server_ip='', server_port='', tokenizer_name='', topk_training=200, training_dir='/home/hojaeson_umass_edu/hojae_workspace/project/ance/data/10/checkpoints_4_bottom_neg_only', world_size=4)
11/28/2024 05:19:36 - INFO - __main__ -   Inference parameters Namespace(ann_chunk_factor=20, ann_dir='/home/hojaeson_umass_edu/hojae_workspace/vector_database/ANCE/outcome/ann_data', ann_measure_topk_mrr=True, bottom_neg=True, bottom_only=True, cache_dir='/home/hojaeson_umass_edu/hojae_workspace/project/ance/data/10/ann_data_4_bottom_neg_onlycache/', config_name='', data_dir='/home/hojaeson_umass_edu/hojae_workspace/vector_database/ANCE/data/10/preprocessed_data', device=device(type='cuda', index=0), end_output_num=-1, inference=False, init_model_dir='/home/hojaeson_umass_edu/hojae_workspace/project/ance/warmup/checkpoint-150000', last_checkpoint_dir='', limit_total_number=100000, load_gen=False, local_rank=0, max_doc_character=10000, max_query_length=64, max_seq_length=512, model_name_or_path='/home/hojaeson_umass_edu/hojae_workspace/project/ance/warmup/checkpoint-150000', model_type='rdot_nll', n_gpu=1, negative_sample=20, no_cuda=False, only_keep_latest_embedding_file=False, output_dir='/home/hojaeson_umass_edu/hojae_workspace/project/ance/data/10/ann_data_4_bottom_neg_only', per_gpu_eval_batch_size=256, rank=0, server_ip='', server_port='', tokenizer_name='', topk_training=200, training_dir='/home/hojaeson_umass_edu/hojae_workspace/project/ance/data/10/checkpoints_4_bottom_neg_only', world_size=4)
***** inference of dev query *****
11/28/2024 05:19:36 - INFO - __main__ -   ***** inference of dev query *****
69806980 -1
 -16980
 -1
6980 -1
***** Running ANN Embedding Inference *****
11/28/2024 05:19:36 - INFO - __main__ -   ***** Running ANN Embedding Inference *****
11/28/2024 05:19:36 - INFO - __main__ -     Batch size = 256
  Batch size = 256
Using mean: False
Using mean: False
Using mean: False
Inferencing: 0it [00:00, ?it/s]502939 -1
884182 -1
11/28/2024 05:19:37 - INFO - __main__ -   Training/evaluation parameters Namespace(adam_epsilon=1e-08, ann_dir='/home/hojaeson_umass_edu/hojae_workspace/vector_database/ANCE/data/10/ann_data_4_bottom_neg_only', cache_dir='', config_name='', data_dir='/home/hojaeson_umass_edu/hojae_workspace/vector_database/ANCE/data/10/preprocessed_data', device=device(type='cuda', index=0), do_lower_case=False, fp16=False, fp16_opt_level='O1', gradient_accumulation_steps=2, learning_rate=1e-06, load_optimizer_scheduler=False, local_rank=0, log_dir=None, logging_steps=100, max_grad_norm=1.0, max_query_length=64, max_seq_length=512, max_steps=1000000, model_name_or_path='/home/hojaeson_umass_edu/hojae_workspace/project/ance/warmup/checkpoint-150000', model_type='rdot_nll', n_gpu=1, no_cuda=False, optimizer='lamb', output_dir='/home/hojaeson_umass_edu/hojae_workspace/vector_database/ANCE/data/10/checkpoints_4_bottom_neg_only', output_mode='classification', per_gpu_train_batch_size=16, rank=0, save_steps=2000, seed=42, server_ip='', server_port='', single_warmup=True, task_name='msmarco', tokenizer_name='', top_neg=0, triplet=True, warmup_steps=5000, weight_decay=0.0, world_size=4)
502939 -1
884182 -1
502939 -1
884182 -1
502939 -1
884182 -1
11/28/2024 05:19:40 - INFO - __main__ -   ***** Running training *****
11/28/2024 05:19:40 - INFO - __main__ -     Max steps = 1000000
11/28/2024 05:19:40 - INFO - __main__ -     Instantaneous batch size per GPU = 16
11/28/2024 05:19:40 - INFO - __main__ -     Total train batch size (w. parallel, distributed & accumulation) = 128
11/28/2024 05:19:40 - INFO - __main__ -     Gradient Accumulation steps = 2
11/28/2024 05:19:40 - INFO - __main__ -     Continuing training from checkpoint, will skip to saved global_step
11/28/2024 05:19:40 - INFO - __main__ -     Continuing training from global step 150000
Inferencing: 7it [00:03,  1.80it/s]
merging embeddings
11/28/2024 05:19:40 - INFO - __main__ -   merging embeddings
11/28/2024 05:19:40 - INFO - __main__ -   Training on new add data at /home/hojaeson_umass_edu/hojae_workspace/vector_database/ANCE/data/10/ann_data_4_bottom_neg_only/ann_training_data_0
/home/hojaeson_umass_edu/hojae_workspace/vector_database/ANCE/data/10/ann_data_4_bottom_neg_only/ann_training_data_0 2735
/home/hojaeson_umass_edu/hojae_workspace/vector_database/ANCE/data/10/ann_data_4_bottom_neg_only/ann_training_data_0 2732 2732
/home/hojaeson_umass_edu/hojae_workspace/vector_database/ANCE/data/10/ann_data_4_bottom_neg_only/ann_training_data_0 2735/home/hojaeson_umass_edu/hojae_workspace/vector_database/ANCE/data/10/ann_data_4_bottom_neg_only/ann_training_data_0
 2735
/home/hojaeson_umass_edu/hojae_workspace/vector_database/ANCE/data/10/ann_data_4_bottom_neg_only/ann_training_data_0 2735
/home/hojaeson_umass_edu/hojae_workspace/vector_database/ANCE/data/10/ann_data_4_bottom_neg_only/ann_training_data_0 2732 2732
/home/hojaeson_umass_edu/hojae_workspace/vector_database/ANCE/data/10/ann_data_4_bottom_neg_only/ann_training_data_0 2732 2732
/home/hojaeson_umass_edu/hojae_workspace/vector_database/ANCE/data/10/ann_data_4_bottom_neg_only/ann_training_data_0 2732 2732
11/28/2024 05:19:40 - INFO - __main__ -   Total ann queries: 2732
dev_ndcg 0.5981032093649599 0
***** inference of passages *****
11/28/2024 05:19:40 - INFO - __main__ -   ***** inference of passages *****
884182 -1
884182 -1
884182 -1
884182 -1
***** Running ANN Embedding Inference *****
11/28/2024 05:19:40 - INFO - __main__ -   ***** Running ANN Embedding Inference *****
  Batch size = 256
11/28/2024 05:19:40 - INFO - __main__ -     Batch size = 256
Inferencing: 0it [00:00, ?it/s]/work/pi_mserafini_umass_edu/hojae/vector_database/ANCE/drivers/../utils/lamb.py:125: UserWarning: This overload of add_ is deprecated:
	add_(Number alpha, Tensor other)
Consider using one of the following signatures instead:
	add_(Tensor other, *, Number alpha) (Triggered internally at  ../torch/csrc/utils/python_arg_parser.cpp:1055.)
  p.data.add_(-step_size * trust_ratio, adam_step)
/work/pi_mserafini_umass_edu/hojae/vector_database/ANCE/drivers/../utils/lamb.py:125: UserWarning: This overload of add_ is deprecated:
	add_(Number alpha, Tensor other)
Consider using one of the following signatures instead:
	add_(Tensor other, *, Number alpha) (Triggered internally at  ../torch/csrc/utils/python_arg_parser.cpp:1055.)
  p.data.add_(-step_size * trust_ratio, adam_step)
/work/pi_mserafini_umass_edu/hojae/vector_database/ANCE/drivers/../utils/lamb.py:125: UserWarning: This overload of add_ is deprecated:
	add_(Number alpha, Tensor other)
Consider using one of the following signatures instead:
	add_(Tensor other, *, Number alpha) (Triggered internally at  ../torch/csrc/utils/python_arg_parser.cpp:1055.)
  p.data.add_(-step_size * trust_ratio, adam_step)
/work/pi_mserafini_umass_edu/hojae/vector_database/ANCE/drivers/../utils/lamb.py:125: UserWarning: This overload of add_ is deprecated:
	add_(Number alpha, Tensor other)
Consider using one of the following signatures instead:
	add_(Tensor other, *, Number alpha) (Triggered internally at  ../torch/csrc/utils/python_arg_parser.cpp:1055.)
  p.data.add_(-step_size * trust_ratio, adam_step)
Inferencing: 0it [00:15, ?it/s]Inferencing: 6it [00:18,  3.05s/it]Inferencing: 7it [00:22,  3.18s/it]Inferencing: 8it [00:25,  3.27s/it]Inferencing: 9it [00:28,  3.09s/it]Inferencing: 10it [00:31,  3.13s/it]Inferencing: 11it [00:35,  3.31s/it]Inferencing: 12it [00:37,  3.09s/it]Inferencing: 13it [00:40,  3.12s/it]Inferencing: 14it [00:44,  3.30s/it]Inferencing: 15it [00:47,  3.22s/it]Inferencing: 16it [00:50,  3.13s/it]Inferencing: 17it [00:54,  3.29s/it]Inferencing: 18it [00:58,  3.44s/it]Inferencing: 19it [01:00,  3.18s/it]Inferencing: 20it [01:03,  3.14s/it]Inferencing: 21it [01:07,  3.33s/it]Inferencing: 22it [01:11,  3.46s/it]Inferencing: 23it [01:14,  3.55s/it]Inferencing: 24it [01:17,  3.25s/it]Inferencing: 25it [01:20,  3.32s/it]Inferencing: 26it [01:24,  3.40s/it]Inferencing: 27it [01:28,  3.47s/it]Inferencing: 28it [01:31,  3.52s/it]Inferencing: 29it [01:35,  3.56s/it]Inferencing: 30it [01:39,  3.56s/it]Inferencing: 31it [01:42,  3.58s/it]Inferencing: 32it [01:46,  3.59s/it]Inferencing: 33it [01:49,  3.57s/it]Inferencing: 34it [01:53,  3.54s/it]Inferencing: 35it [01:56,  3.55s/it]Inferencing: 36it [02:00,  3.55s/it]Inferencing: 37it [02:04,  3.58s/it]Inferencing: 38it [02:07,  3.57s/it]Inferencing: 39it [02:11,  3.59s/it]Inferencing: 40it [02:14,  3.58s/it]Inferencing: 41it [02:18,  3.58s/it]Inferencing: 42it [02:21,  3.57s/it]Inferencing: 43it [02:25,  3.55s/it]Inferencing: 44it [02:29,  3.57s/it]Inferencing: 45it [02:32,  3.58s/it]Inferencing: 46it [02:36,  3.55s/it]Inferencing: 47it [02:39,  3.56s/it]Inferencing: 48it [02:43,  3.58s/it]Inferencing: 49it [02:46,  3.57s/it]Inferencing: 50it [02:50,  3.60s/it]Inferencing: 51it [02:54,  3.58s/it]Inferencing: 52it [02:57,  3.55s/it]Inferencing: 53it [03:01,  3.57s/it]Inferencing: 54it [03:04,  3.59s/it]Inferencing: 55it [03:08,  3.58s/it]Inferencing: 56it [03:11,  3.59s/it]Inferencing: 57it [03:15,  3.58s/it]Inferencing: 58it [03:18,  3.54s/it]Inferencing: 59it [03:22,  3.53s/it]Inferencing: 60it [03:26,  3.53s/it]Inferencing: 61it [03:29,  3.53s/it]Inferencing: 62it [03:33,  3.54s/it]Inferencing: 63it [03:36,  3.56s/it]Inferencing: 64it [03:40,  3.56s/it]Inferencing: 65it [03:43,  3.55s/it]Inferencing: 66it [03:47,  3.57s/it]Inferencing: 67it [03:51,  3.58s/it]Inferencing: 68it [03:54,  3.59s/it]Inferencing: 69it [03:58,  3.57s/it]Inferencing: 70it [04:01,  3.58s/it]Inferencing: 71it [04:05,  3.57s/it]Inferencing: 72it [04:08,  3.58s/it]Inferencing: 73it [04:12,  3.56s/it]Inferencing: 74it [04:15,  3.55s/it]Inferencing: 75it [04:19,  3.57s/it]Inferencing: 76it [04:23,  3.55s/it]Inferencing: 77it [04:26,  3.55s/it]Inferencing: 78it [04:30,  3.56s/it]Inferencing: 79it [04:33,  3.53s/it]Inferencing: 80it [04:37,  3.55s/it]Inferencing: 81it [04:40,  3.54s/it]Inferencing: 82it [04:44,  3.52s/it]Inferencing: 83it [04:47,  3.52s/it]Inferencing: 84it [04:51,  3.54s/it]Inferencing: 85it [04:54,  3.55s/it]Inferencing: 86it [04:58,  3.53s/it]Inferencing: 87it [05:01,  3.51s/it]Inferencing: 88it [05:05,  3.53s/it]Inferencing: 89it [05:09,  3.55s/it]Inferencing: 90it [05:12,  3.56s/it]Inferencing: 91it [05:16,  3.56s/it]Inferencing: 92it [05:19,  3.53s/it]Inferencing: 93it [05:23,  3.52s/it]Inferencing: 94it [05:26,  3.55s/it]Inferencing: 95it [05:30,  3.56s/it]Inferencing: 96it [05:33,  3.58s/it]Inferencing: 97it [05:37,  3.55s/it]Inferencing: 98it [05:41,  3.55s/it]Inferencing: 99it [05:44,  3.57s/it]Inferencing: 100it [05:48,  3.58s/it]Inferencing: 101it [05:51,  3.59s/it]Inferencing: 102it [05:55,  3.59s/it]Inferencing: 103it [05:59,  3.60s/it]Inferencing: 104it [06:02,  3.61s/it]Inferencing: 105it [06:06,  3.58s/it]Inferencing: 106it [06:09,  3.58s/it]Inferencing: 107it [06:13,  3.59s/it]/home/hojaeson_umass_edu/hojae_workspace/miniconda3/envs/ance/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:249: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.
  warnings.warn("To get the last learning rate computed by the scheduler, "
/home/hojaeson_umass_edu/hojae_workspace/miniconda3/envs/ance/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:249: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.
  warnings.warn("To get the last learning rate computed by the scheduler, "
11/28/2024 05:25:54 - INFO - __main__ -   {"learning_rate": 2e-08, "loss": 0.14315316681810628, "step": 150100}
{"learning_rate": 2e-08, "loss": 0.14315316681810628, "step": 150100}
/home/hojaeson_umass_edu/hojae_workspace/miniconda3/envs/ance/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:249: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.
  warnings.warn("To get the last learning rate computed by the scheduler, "
/home/hojaeson_umass_edu/hojae_workspace/miniconda3/envs/ance/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:249: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.
  warnings.warn("To get the last learning rate computed by the scheduler, "
Inferencing: 108it [06:16,  3.57s/it]Inferencing: 109it [06:20,  3.55s/it]Inferencing: 110it [06:23,  3.54s/it]Inferencing: 111it [06:27,  3.53s/it]Inferencing: 112it [06:31,  3.54s/it]Inferencing: 113it [06:34,  3.52s/it]Inferencing: 114it [06:38,  3.54s/it]Inferencing: 115it [06:41,  3.56s/it]Inferencing: 116it [06:45,  3.53s/it]Inferencing: 117it [06:48,  3.53s/it]Inferencing: 118it [06:52,  3.54s/it]Inferencing: 119it [06:55,  3.52s/it]Inferencing: 120it [06:59,  3.53s/it]Inferencing: 121it [07:02,  3.53s/it]Inferencing: 122it [07:06,  3.54s/it]Inferencing: 123it [07:09,  3.56s/it]Inferencing: 124it [07:13,  3.55s/it]Inferencing: 125it [07:17,  3.57s/it]Inferencing: 126it [07:20,  3.53s/it]Inferencing: 127it [07:24,  3.51s/it]Inferencing: 128it [07:27,  3.52s/it]Inferencing: 129it [07:31,  3.54s/it]Inferencing: 130it [07:34,  3.56s/it]Inferencing: 131it [07:38,  3.55s/it]Inferencing: 132it [07:41,  3.57s/it]Inferencing: 133it [07:45,  3.56s/it]Inferencing: 134it [07:49,  3.57s/it]Inferencing: 135it [07:52,  3.57s/it]Inferencing: 136it [07:56,  3.56s/it]Inferencing: 137it [07:59,  3.56s/it]Inferencing: 138it [08:03,  3.52s/it]Inferencing: 139it [08:06,  3.55s/it]Inferencing: 140it [08:10,  3.54s/it]Inferencing: 141it [08:13,  3.55s/it]Inferencing: 142it [08:17,  3.52s/it]Inferencing: 143it [08:20,  3.52s/it]Inferencing: 144it [08:24,  3.53s/it]Inferencing: 145it [08:27,  3.52s/it]Inferencing: 146it [08:31,  3.51s/it]Inferencing: 147it [08:34,  3.53s/it]Inferencing: 148it [08:38,  3.53s/it]Inferencing: 149it [08:42,  3.54s/it]Inferencing: 150it [08:45,  3.54s/it]Inferencing: 151it [08:49,  3.54s/it]Inferencing: 152it [08:52,  3.55s/it]Inferencing: 153it [08:56,  3.55s/it]Inferencing: 154it [08:59,  3.57s/it]Inferencing: 155it [09:03,  3.57s/it]Inferencing: 156it [09:06,  3.56s/it]Inferencing: 157it [09:10,  3.57s/it]Inferencing: 158it [09:14,  3.56s/it]Inferencing: 159it [09:17,  3.56s/it]Inferencing: 160it [09:21,  3.56s/it]Inferencing: 161it [09:24,  3.55s/it]Inferencing: 162it [09:28,  3.56s/it]Inferencing: 163it [09:31,  3.56s/it]Inferencing: 164it [09:35,  3.58s/it]Inferencing: 165it [09:38,  3.54s/it]Inferencing: 166it [09:42,  3.56s/it]Inferencing: 167it [09:46,  3.54s/it]Inferencing: 168it [09:49,  3.54s/it]Inferencing: 169it [09:53,  3.53s/it]Inferencing: 170it [09:56,  3.55s/it]Inferencing: 171it [10:00,  3.54s/it]Inferencing: 172it [10:03,  3.55s/it]Inferencing: 173it [10:07,  3.57s/it]Inferencing: 174it [10:10,  3.55s/it]Inferencing: 175it [10:14,  3.56s/it]Inferencing: 176it [10:18,  3.56s/it]Inferencing: 177it [10:21,  3.57s/it]Inferencing: 178it [10:25,  3.59s/it]Inferencing: 179it [10:28,  3.59s/it]Inferencing: 180it [10:32,  3.60s/it]Inferencing: 181it [10:35,  3.56s/it]Inferencing: 182it [10:39,  3.57s/it]Inferencing: 183it [10:43,  3.55s/it]Inferencing: 184it [10:46,  3.57s/it]Inferencing: 185it [10:50,  3.56s/it]Inferencing: 186it [10:53,  3.56s/it]Inferencing: 187it [10:57,  3.58s/it]Inferencing: 188it [11:00,  3.56s/it]Inferencing: 189it [11:04,  3.53s/it]Inferencing: 190it [11:07,  3.53s/it]Inferencing: 191it [11:11,  3.55s/it]Inferencing: 192it [11:15,  3.55s/it]Inferencing: 193it [11:18,  3.53s/it]Inferencing: 194it [11:22,  3.54s/it]Inferencing: 195it [11:25,  3.53s/it]Inferencing: 196it [11:29,  3.56s/it]Inferencing: 197it [11:32,  3.57s/it]Inferencing: 198it [11:36,  3.56s/it]Inferencing: 199it [11:39,  3.55s/it]Inferencing: 200it [11:43,  3.52s/it]Inferencing: 201it [11:46,  3.55s/it]Inferencing: 202it [11:50,  3.55s/it]Inferencing: 203it [11:54,  3.53s/it]Inferencing: 204it [11:57,  3.52s/it]Inferencing: 205it [12:01,  3.53s/it]Inferencing: 206it [12:04,  3.53s/it]Inferencing: 207it [12:08,  3.53s/it]11/28/2024 05:31:49 - INFO - __main__ -   {"learning_rate": 4e-08, "loss": 0.2106960218805, "step": 150200}
{"learning_rate": 4e-08, "loss": 0.2106960218805, "step": 150200}
Inferencing: 208it [12:11,  3.56s/it]Inferencing: 209it [12:15,  3.56s/it]Inferencing: 210it [12:18,  3.53s/it]Inferencing: 211it [12:22,  3.52s/it]Inferencing: 212it [12:25,  3.51s/it]Inferencing: 213it [12:29,  3.53s/it]Inferencing: 214it [12:32,  3.51s/it]Inferencing: 215it [12:36,  3.53s/it]Inferencing: 216it [12:39,  3.54s/it]Inferencing: 217it [12:43,  3.56s/it]Inferencing: 218it [12:47,  3.57s/it]Inferencing: 219it [12:50,  3.56s/it]Inferencing: 220it [12:54,  3.57s/it]Inferencing: 221it [12:57,  3.57s/it]Inferencing: 222it [13:01,  3.58s/it]Inferencing: 223it [13:04,  3.57s/it]Inferencing: 224it [13:08,  3.58s/it]Inferencing: 225it [13:12,  3.59s/it]Inferencing: 226it [13:15,  3.60s/it]Inferencing: 227it [13:19,  3.59s/it]Inferencing: 228it [13:22,  3.59s/it]Inferencing: 229it [13:26,  3.56s/it]Inferencing: 230it [13:29,  3.54s/it]Inferencing: 231it [13:33,  3.56s/it]Inferencing: 232it [13:37,  3.57s/it]Inferencing: 233it [13:40,  3.55s/it]Inferencing: 234it [13:44,  3.57s/it]Inferencing: 235it [13:47,  3.55s/it]Inferencing: 236it [13:51,  3.53s/it]Inferencing: 237it [13:54,  3.55s/it]Inferencing: 238it [13:58,  3.54s/it]Inferencing: 239it [14:01,  3.53s/it]Inferencing: 240it [14:05,  3.55s/it]Inferencing: 241it [14:08,  3.54s/it]Inferencing: 242it [14:12,  3.51s/it]Inferencing: 243it [14:16,  3.54s/it]Inferencing: 244it [14:19,  3.54s/it]Inferencing: 245it [14:23,  3.54s/it]Inferencing: 246it [14:26,  3.55s/it]Inferencing: 247it [14:30,  3.52s/it]Inferencing: 248it [14:33,  3.52s/it]Inferencing: 249it [14:37,  3.51s/it]Inferencing: 250it [14:40,  3.51s/it]Inferencing: 251it [14:44,  3.52s/it]Inferencing: 252it [14:47,  3.50s/it]Inferencing: 253it [14:51,  3.50s/it]Inferencing: 254it [14:54,  3.54s/it]Inferencing: 255it [14:58,  3.53s/it]Inferencing: 256it [15:01,  3.55s/it]Inferencing: 257it [15:05,  3.57s/it]Inferencing: 258it [15:09,  3.58s/it]Inferencing: 259it [15:12,  3.55s/it]Inferencing: 260it [15:16,  3.55s/it]Inferencing: 261it [15:19,  3.55s/it]Inferencing: 262it [15:23,  3.54s/it]Inferencing: 263it [15:26,  3.53s/it]Inferencing: 264it [15:30,  3.53s/it]Inferencing: 265it [15:33,  3.54s/it]Inferencing: 266it [15:37,  3.53s/it]Inferencing: 267it [15:40,  3.55s/it]Inferencing: 268it [15:44,  3.54s/it]Inferencing: 269it [15:48,  3.56s/it]Inferencing: 270it [15:51,  3.54s/it]Inferencing: 271it [15:55,  3.56s/it]Inferencing: 272it [15:58,  3.57s/it]Inferencing: 273it [16:02,  3.57s/it]Inferencing: 274it [16:05,  3.56s/it]Inferencing: 275it [16:09,  3.55s/it]Inferencing: 276it [16:12,  3.52s/it]Inferencing: 277it [16:16,  3.55s/it]Inferencing: 278it [16:20,  3.57s/it]Inferencing: 279it [16:23,  3.58s/it]Inferencing: 280it [16:27,  3.59s/it]Inferencing: 281it [16:30,  3.60s/it]Inferencing: 282it [16:34,  3.58s/it]Inferencing: 283it [16:37,  3.55s/it]Inferencing: 284it [16:41,  3.53s/it]Inferencing: 285it [16:44,  3.54s/it]Inferencing: 286it [16:48,  3.55s/it]Inferencing: 287it [16:52,  3.53s/it]Inferencing: 288it [16:55,  3.55s/it]Inferencing: 289it [16:59,  3.54s/it]Inferencing: 290it [17:02,  3.54s/it]Inferencing: 291it [17:06,  3.53s/it]Inferencing: 292it [17:09,  3.56s/it]Inferencing: 293it [17:13,  3.56s/it]Inferencing: 294it [17:16,  3.58s/it]Inferencing: 295it [17:20,  3.56s/it]Inferencing: 296it [17:24,  3.57s/it]Inferencing: 297it [17:27,  3.58s/it]Inferencing: 298it [17:31,  3.59s/it]Inferencing: 299it [17:34,  3.60s/it]Inferencing: 300it [17:38,  3.59s/it]Inferencing: 301it [17:41,  3.55s/it]Inferencing: 302it [17:45,  3.52s/it]Inferencing: 303it [17:48,  3.53s/it]Inferencing: 304it [17:52,  3.53s/it]Inferencing: 305it [17:56,  3.54s/it]Inferencing: 306it [17:59,  3.53s/it]Inferencing: 307it [18:03,  3.52s/it]11/28/2024 05:37:44 - INFO - __main__ -   {"learning_rate": 6e-08, "loss": 0.15504579647051003, "step": 150300}
{"learning_rate": 6e-08, "loss": 0.15504579647051003, "step": 150300}
Inferencing: 308it [18:06,  3.52s/it]Inferencing: 309it [18:10,  3.54s/it]Inferencing: 310it [18:13,  3.52s/it]Inferencing: 311it [18:17,  3.51s/it]Inferencing: 312it [18:20,  3.54s/it]Inferencing: 313it [18:24,  3.56s/it]Inferencing: 314it [18:27,  3.55s/it]Inferencing: 315it [18:31,  3.53s/it]Inferencing: 316it [18:34,  3.53s/it]Inferencing: 317it [18:38,  3.52s/it]Inferencing: 318it [18:42,  3.55s/it]Inferencing: 319it [18:45,  3.55s/it]Inferencing: 320it [18:49,  3.57s/it]Inferencing: 321it [18:52,  3.58s/it]Inferencing: 322it [18:56,  3.54s/it]Inferencing: 323it [18:59,  3.54s/it]Inferencing: 324it [19:03,  3.54s/it]Inferencing: 325it [19:06,  3.56s/it]Inferencing: 326it [19:10,  3.56s/it]Inferencing: 327it [19:14,  3.57s/it]Inferencing: 328it [19:17,  3.58s/it]Inferencing: 329it [19:21,  3.55s/it]Inferencing: 330it [19:24,  3.57s/it]Inferencing: 331it [19:28,  3.58s/it]Inferencing: 332it [19:31,  3.59s/it]Inferencing: 333it [19:35,  3.57s/it]Inferencing: 334it [19:39,  3.57s/it]Inferencing: 335it [19:42,  3.57s/it]Inferencing: 336it [19:46,  3.56s/it]Inferencing: 337it [19:49,  3.57s/it]Inferencing: 338it [19:53,  3.57s/it]Inferencing: 339it [19:56,  3.54s/it]Inferencing: 340it [20:00,  3.53s/it]Inferencing: 341it [20:03,  3.56s/it]Inferencing: 342it [20:07,  3.54s/it]Inferencing: 343it [20:10,  3.53s/it]Inferencing: 344it [20:14,  3.52s/it]Inferencing: 345it [20:18,  3.55s/it]Inferencing: 346it [20:21,  3.57s/it]Inferencing: 347it [20:25,  3.55s/it]Inferencing: 348it [20:28,  3.52s/it]Inferencing: 349it [20:32,  3.52s/it]Inferencing: 350it [20:35,  3.51s/it]Inferencing: 351it [20:39,  3.53s/it]Inferencing: 352it [20:42,  3.51s/it]Inferencing: 353it [20:46,  3.49s/it]Inferencing: 354it [20:49,  3.50s/it]Inferencing: 355it [20:53,  3.53s/it]Inferencing: 356it [20:56,  3.53s/it]Inferencing: 357it [21:00,  3.55s/it]Inferencing: 358it [21:03,  3.54s/it]Inferencing: 359it [21:07,  3.56s/it]Inferencing: 360it [21:11,  3.56s/it]Inferencing: 361it [21:14,  3.57s/it]Inferencing: 362it [21:18,  3.58s/it]Inferencing: 363it [21:21,  3.56s/it]Inferencing: 364it [21:25,  3.53s/it]Inferencing: 365it [21:28,  3.53s/it]Inferencing: 366it [21:32,  3.53s/it]Inferencing: 367it [21:35,  3.56s/it]Inferencing: 368it [21:39,  3.56s/it]Inferencing: 369it [21:43,  3.57s/it]Inferencing: 370it [21:46,  3.58s/it]Inferencing: 371it [21:50,  3.58s/it]Inferencing: 372it [21:53,  3.55s/it]Inferencing: 373it [21:57,  3.55s/it]Inferencing: 374it [22:00,  3.54s/it]Inferencing: 375it [22:04,  3.57s/it]Inferencing: 376it [22:07,  3.55s/it]Inferencing: 377it [22:11,  3.57s/it]Inferencing: 378it [22:15,  3.54s/it]Inferencing: 379it [22:18,  3.53s/it]Inferencing: 380it [22:22,  3.51s/it]Inferencing: 381it [22:25,  3.52s/it]Inferencing: 382it [22:29,  3.52s/it]Inferencing: 383it [22:32,  3.52s/it]Inferencing: 384it [22:36,  3.55s/it]Inferencing: 385it [22:39,  3.57s/it]Inferencing: 386it [22:43,  3.57s/it]Inferencing: 387it [22:46,  3.57s/it]Inferencing: 388it [22:50,  3.56s/it]Inferencing: 389it [22:54,  3.55s/it]Inferencing: 390it [22:57,  3.53s/it]Inferencing: 391it [23:01,  3.53s/it]Inferencing: 392it [23:04,  3.56s/it]Inferencing: 393it [23:08,  3.54s/it]Inferencing: 394it [23:11,  3.55s/it]Inferencing: 395it [23:15,  3.54s/it]Inferencing: 396it [23:18,  3.53s/it]Inferencing: 397it [23:22,  3.54s/it]Inferencing: 398it [23:25,  3.56s/it]Inferencing: 399it [23:29,  3.54s/it]Inferencing: 400it [23:32,  3.52s/it]Inferencing: 401it [23:36,  3.51s/it]Inferencing: 402it [23:39,  3.50s/it]Inferencing: 403it [23:43,  3.53s/it]Inferencing: 404it [23:47,  3.54s/it]Inferencing: 405it [23:50,  3.56s/it]Inferencing: 406it [23:54,  3.57s/it]Inferencing: 407it [23:57,  3.58s/it]11/28/2024 05:43:38 - INFO - __main__ -   {"learning_rate": 8e-08, "loss": 0.24504488546162634, "step": 150400}
{"learning_rate": 8e-08, "loss": 0.24504488546162634, "step": 150400}
Inferencing: 408it [24:01,  3.56s/it]Inferencing: 409it [24:04,  3.55s/it]Inferencing: 410it [24:08,  3.56s/it]Inferencing: 411it [24:12,  3.56s/it]Inferencing: 412it [24:15,  3.57s/it]Inferencing: 413it [24:19,  3.55s/it]Inferencing: 414it [24:22,  3.55s/it]Inferencing: 415it [24:26,  3.56s/it]Inferencing: 416it [24:29,  3.58s/it]Inferencing: 417it [24:33,  3.59s/it]Inferencing: 418it [24:37,  3.58s/it]Inferencing: 419it [24:40,  3.59s/it]Inferencing: 420it [24:44,  3.58s/it]Inferencing: 421it [24:47,  3.58s/it]Inferencing: 422it [24:51,  3.56s/it]Inferencing: 423it [24:54,  3.54s/it]Inferencing: 424it [24:58,  3.56s/it]Inferencing: 425it [25:02,  3.56s/it]Inferencing: 426it [25:05,  3.56s/it]Inferencing: 427it [25:09,  3.56s/it]Inferencing: 428it [25:12,  3.55s/it]Inferencing: 429it [25:16,  3.56s/it]Inferencing: 430it [25:19,  3.57s/it]Inferencing: 431it [25:23,  3.57s/it]Inferencing: 432it [25:26,  3.57s/it]Inferencing: 433it [25:30,  3.57s/it]Inferencing: 434it [25:33,  3.53s/it]11/28/2024 05:45:14 - INFO - __main__ -   Finished iterating current dataset, begin reiterate
Inferencing: 435it [25:37,  3.54s/it]Inferencing: 436it [25:41,  3.53s/it]Inferencing: 437it [25:44,  3.52s/it]Inferencing: 438it [25:48,  3.54s/it]Inferencing: 439it [25:51,  3.53s/it]Inferencing: 440it [25:55,  3.55s/it]Inferencing: 441it [25:58,  3.56s/it]Inferencing: 442it [26:02,  3.54s/it]Inferencing: 443it [26:05,  3.56s/it]Inferencing: 444it [26:09,  3.53s/it]Inferencing: 445it [26:12,  3.53s/it]Inferencing: 446it [26:16,  3.51s/it]Inferencing: 447it [26:19,  3.51s/it]Inferencing: 448it [26:23,  3.52s/it]Inferencing: 449it [26:27,  3.55s/it]Inferencing: 450it [26:30,  3.57s/it]Inferencing: 451it [26:34,  3.54s/it]Inferencing: 452it [26:37,  3.55s/it]Inferencing: 453it [26:41,  3.57s/it]Inferencing: 454it [26:44,  3.54s/it]Inferencing: 455it [26:48,  3.55s/it]Inferencing: 456it [26:51,  3.52s/it]Inferencing: 457it [26:55,  3.51s/it]Inferencing: 458it [26:58,  3.51s/it]Inferencing: 459it [27:02,  3.54s/it]Inferencing: 460it [27:05,  3.52s/it]Inferencing: 461it [27:09,  3.52s/it]Inferencing: 462it [27:12,  3.53s/it]Inferencing: 463it [27:16,  3.53s/it]Inferencing: 464it [27:19,  3.51s/it]Inferencing: 465it [27:23,  3.52s/it]Inferencing: 466it [27:27,  3.53s/it]Inferencing: 467it [27:30,  3.51s/it]Inferencing: 468it [27:34,  3.53s/it]Inferencing: 469it [27:37,  3.55s/it]Inferencing: 470it [27:41,  3.55s/it]Inferencing: 471it [27:44,  3.56s/it]Inferencing: 472it [27:48,  3.58s/it]Inferencing: 473it [27:52,  3.59s/it]Inferencing: 474it [27:55,  3.60s/it]Inferencing: 475it [27:59,  3.56s/it]Inferencing: 476it [28:02,  3.54s/it]Inferencing: 477it [28:06,  3.56s/it]Inferencing: 478it [28:09,  3.55s/it]Inferencing: 479it [28:13,  3.56s/it]Inferencing: 480it [28:16,  3.53s/it]Inferencing: 481it [28:20,  3.51s/it]Inferencing: 482it [28:23,  3.51s/it]Inferencing: 483it [28:27,  3.50s/it]Inferencing: 484it [28:30,  3.52s/it]Inferencing: 485it [28:34,  3.55s/it]Inferencing: 486it [28:37,  3.53s/it]Inferencing: 487it [28:41,  3.54s/it]Inferencing: 488it [28:45,  3.56s/it]Inferencing: 489it [28:48,  3.56s/it]Inferencing: 490it [28:52,  3.56s/it]Inferencing: 491it [28:55,  3.53s/it]Inferencing: 492it [28:59,  3.55s/it]Inferencing: 493it [29:02,  3.52s/it]Inferencing: 494it [29:06,  3.50s/it]Inferencing: 495it [29:09,  3.52s/it]Inferencing: 496it [29:13,  3.50s/it]Inferencing: 497it [29:16,  3.50s/it]Inferencing: 498it [29:20,  3.52s/it]Inferencing: 499it [29:23,  3.55s/it]Inferencing: 500it [29:27,  3.53s/it]Inferencing: 501it [29:30,  3.56s/it]Inferencing: 502it [29:34,  3.56s/it]Inferencing: 503it [29:38,  3.55s/it]Inferencing: 504it [29:41,  3.55s/it]Inferencing: 505it [29:45,  3.57s/it]Inferencing: 506it [29:48,  3.55s/it]Inferencing: 507it [29:52,  3.55s/it]11/28/2024 05:49:33 - INFO - __main__ -   {"learning_rate": 1e-07, "loss": 0.16863126717633556, "step": 150500}
{"learning_rate": 1e-07, "loss": 0.16863126717633556, "step": 150500}
Inferencing: 508it [29:55,  3.53s/it]Inferencing: 509it [29:59,  3.51s/it]Inferencing: 510it [30:02,  3.54s/it]Inferencing: 511it [30:06,  3.56s/it]Inferencing: 512it [30:10,  3.58s/it]Inferencing: 513it [30:13,  3.57s/it]Inferencing: 514it [30:17,  3.56s/it]Inferencing: 515it [30:20,  3.53s/it]Inferencing: 516it [30:24,  3.52s/it]Inferencing: 517it [30:27,  3.52s/it]Inferencing: 518it [30:31,  3.55s/it]Inferencing: 519it [30:34,  3.55s/it]Inferencing: 520it [30:38,  3.56s/it]Inferencing: 521it [30:41,  3.56s/it]Inferencing: 522it [30:45,  3.56s/it]Inferencing: 523it [30:49,  3.58s/it]Inferencing: 524it [30:52,  3.54s/it]Inferencing: 525it [30:56,  3.53s/it]Inferencing: 526it [30:59,  3.53s/it]Inferencing: 527it [31:03,  3.51s/it]Inferencing: 528it [31:06,  3.54s/it]Inferencing: 529it [31:10,  3.53s/it]Inferencing: 530it [31:13,  3.54s/it]Inferencing: 531it [31:17,  3.56s/it]Inferencing: 532it [31:20,  3.58s/it]Inferencing: 533it [31:24,  3.56s/it]Inferencing: 534it [31:28,  3.56s/it]Inferencing: 535it [31:31,  3.58s/it]Inferencing: 536it [31:35,  3.57s/it]Inferencing: 537it [31:38,  3.57s/it]Inferencing: 538it [31:42,  3.55s/it]Inferencing: 539it [31:45,  3.52s/it]Inferencing: 540it [31:49,  3.54s/it]Inferencing: 541it [31:52,  3.54s/it]Inferencing: 542it [31:56,  3.55s/it]Inferencing: 543it [32:00,  3.55s/it]Inferencing: 544it [32:03,  3.57s/it]Inferencing: 545it [32:07,  3.57s/it]Inferencing: 546it [32:10,  3.54s/it]Inferencing: 547it [32:14,  3.56s/it]Inferencing: 548it [32:17,  3.58s/it]Inferencing: 549it [32:21,  3.58s/it]Inferencing: 550it [32:25,  3.59s/it]Inferencing: 551it [32:28,  3.59s/it]Inferencing: 552it [32:32,  3.60s/it]Inferencing: 553it [32:35,  3.58s/it]Inferencing: 554it [32:39,  3.59s/it]Inferencing: 555it [32:43,  3.60s/it]Inferencing: 556it [32:46,  3.58s/it]Inferencing: 557it [32:50,  3.55s/it]Inferencing: 558it [32:53,  3.53s/it]Inferencing: 559it [32:57,  3.52s/it]Inferencing: 560it [33:00,  3.50s/it]Inferencing: 561it [33:04,  3.54s/it]Inferencing: 562it [33:07,  3.53s/it]Inferencing: 563it [33:11,  3.52s/it]Inferencing: 564it [33:14,  3.54s/it]Inferencing: 565it [33:18,  3.56s/it]Inferencing: 566it [33:21,  3.56s/it]Inferencing: 567it [33:25,  3.55s/it]Inferencing: 568it [33:29,  3.56s/it]Inferencing: 569it [33:32,  3.58s/it]Inferencing: 570it [33:36,  3.54s/it]Inferencing: 571it [33:39,  3.54s/it]Inferencing: 572it [33:43,  3.55s/it]Inferencing: 573it [33:46,  3.54s/it]Inferencing: 574it [33:50,  3.56s/it]Inferencing: 575it [33:53,  3.57s/it]Inferencing: 576it [33:57,  3.55s/it]Inferencing: 577it [34:01,  3.55s/it]Inferencing: 578it [34:04,  3.55s/it]Inferencing: 579it [34:08,  3.54s/it]Inferencing: 580it [34:11,  3.56s/it]Inferencing: 581it [34:15,  3.54s/it]Inferencing: 582it [34:18,  3.54s/it]Inferencing: 583it [34:22,  3.56s/it]Inferencing: 584it [34:25,  3.58s/it]Inferencing: 585it [34:29,  3.58s/it]Inferencing: 586it [34:33,  3.57s/it]Inferencing: 587it [34:36,  3.57s/it]Inferencing: 588it [34:40,  3.57s/it]Inferencing: 589it [34:43,  3.58s/it]Inferencing: 590it [34:47,  3.58s/it]Inferencing: 591it [34:51,  3.59s/it]Inferencing: 592it [34:54,  3.55s/it]Inferencing: 593it [34:57,  3.52s/it]Inferencing: 594it [35:01,  3.50s/it]Inferencing: 595it [35:04,  3.50s/it]Inferencing: 596it [35:08,  3.53s/it]Inferencing: 597it [35:12,  3.56s/it]Inferencing: 598it [35:15,  3.55s/it]Inferencing: 599it [35:19,  3.57s/it]Inferencing: 600it [35:22,  3.57s/it]Inferencing: 601it [35:26,  3.56s/it]Inferencing: 602it [35:29,  3.58s/it]Inferencing: 603it [35:33,  3.59s/it]Inferencing: 604it [35:37,  3.57s/it]Inferencing: 605it [35:40,  3.53s/it]Inferencing: 606it [35:44,  3.53s/it]Inferencing: 607it [35:47,  3.52s/it]11/28/2024 05:55:28 - INFO - __main__ -   {"learning_rate": 1.2e-07, "loss": 0.1900371497497565, "step": 150600}
{"learning_rate": 1.2e-07, "loss": 0.1900371497497565, "step": 150600}
Inferencing: 608it [35:51,  3.52s/it]Inferencing: 609it [35:54,  3.52s/it]Inferencing: 610it [35:58,  3.51s/it]Inferencing: 611it [36:01,  3.50s/it]Inferencing: 612it [36:05,  3.53s/it]Inferencing: 613it [36:08,  3.54s/it]Inferencing: 614it [36:12,  3.56s/it]Inferencing: 615it [36:15,  3.56s/it]Inferencing: 616it [36:19,  3.54s/it]Inferencing: 617it [36:23,  3.55s/it]Inferencing: 618it [36:26,  3.55s/it]Inferencing: 619it [36:30,  3.56s/it]Inferencing: 620it [36:33,  3.58s/it]Inferencing: 621it [36:37,  3.59s/it]Inferencing: 622it [36:40,  3.56s/it]Inferencing: 623it [36:44,  3.55s/it]Inferencing: 624it [36:47,  3.54s/it]Inferencing: 625it [36:51,  3.54s/it]Inferencing: 626it [36:55,  3.56s/it]Inferencing: 627it [36:58,  3.57s/it]Inferencing: 628it [37:02,  3.56s/it]Inferencing: 629it [37:05,  3.57s/it]Inferencing: 630it [37:09,  3.58s/it]Inferencing: 631it [37:12,  3.58s/it]Inferencing: 632it [37:16,  3.57s/it]Inferencing: 633it [37:20,  3.58s/it]Inferencing: 634it [37:23,  3.57s/it]Inferencing: 635it [37:27,  3.57s/it]Inferencing: 636it [37:30,  3.58s/it]Inferencing: 637it [37:34,  3.57s/it]Inferencing: 638it [37:37,  3.58s/it]Inferencing: 639it [37:41,  3.59s/it]Inferencing: 640it [37:45,  3.60s/it]Inferencing: 641it [37:48,  3.60s/it]Inferencing: 642it [37:52,  3.60s/it]Inferencing: 643it [37:55,  3.56s/it]Inferencing: 644it [37:59,  3.54s/it]Inferencing: 645it [38:02,  3.55s/it]Inferencing: 646it [38:06,  3.54s/it]Inferencing: 647it [38:10,  3.56s/it]Inferencing: 648it [38:13,  3.57s/it]Inferencing: 649it [38:17,  3.58s/it]Inferencing: 650it [38:20,  3.58s/it]Inferencing: 651it [38:24,  3.56s/it]Inferencing: 652it [38:27,  3.57s/it]Inferencing: 653it [38:31,  3.57s/it]Inferencing: 654it [38:35,  3.56s/it]Inferencing: 655it [38:38,  3.54s/it]Inferencing: 656it [38:42,  3.55s/it]Inferencing: 657it [38:45,  3.57s/it]Inferencing: 658it [38:49,  3.55s/it]Inferencing: 659it [38:52,  3.56s/it]Inferencing: 660it [38:56,  3.53s/it]Inferencing: 661it [38:59,  3.54s/it]Inferencing: 662it [39:03,  3.52s/it]Inferencing: 663it [39:06,  3.52s/it]Inferencing: 664it [39:10,  3.50s/it]Inferencing: 665it [39:13,  3.52s/it]Inferencing: 666it [39:17,  3.52s/it]Inferencing: 667it [39:20,  3.50s/it]Inferencing: 668it [39:24,  3.50s/it]Inferencing: 669it [39:27,  3.53s/it]Inferencing: 670it [39:31,  3.55s/it]Inferencing: 671it [39:35,  3.56s/it]Inferencing: 672it [39:38,  3.56s/it]Inferencing: 673it [39:42,  3.56s/it]Inferencing: 674it [39:45,  3.57s/it]Inferencing: 675it [39:49,  3.58s/it]Inferencing: 676it [39:53,  3.59s/it]Inferencing: 677it [39:56,  3.60s/it]Inferencing: 678it [40:00,  3.57s/it]Inferencing: 679it [40:03,  3.58s/it]Inferencing: 680it [40:07,  3.56s/it]Inferencing: 681it [40:10,  3.56s/it]Inferencing: 682it [40:14,  3.54s/it]Inferencing: 683it [40:17,  3.56s/it]Inferencing: 684it [40:21,  3.55s/it]Inferencing: 685it [40:25,  3.56s/it]Inferencing: 686it [40:28,  3.58s/it]Inferencing: 687it [40:32,  3.56s/it]Inferencing: 688it [40:35,  3.53s/it]Inferencing: 689it [40:39,  3.56s/it]Inferencing: 690it [40:42,  3.55s/it]Inferencing: 691it [40:46,  3.54s/it]Inferencing: 692it [40:49,  3.55s/it]Inferencing: 693it [40:53,  3.56s/it]Inferencing: 694it [40:57,  3.58s/it]Inferencing: 695it [41:00,  3.56s/it]Inferencing: 696it [41:04,  3.55s/it]Inferencing: 697it [41:07,  3.54s/it]Inferencing: 698it [41:11,  3.56s/it]Inferencing: 699it [41:14,  3.55s/it]Inferencing: 700it [41:18,  3.54s/it]Inferencing: 701it [41:21,  3.54s/it]Inferencing: 702it [41:25,  3.55s/it]Inferencing: 703it [41:28,  3.57s/it]Inferencing: 704it [41:32,  3.57s/it]Inferencing: 705it [41:36,  3.55s/it]Inferencing: 706it [41:39,  3.54s/it]Inferencing: 707it [41:43,  3.55s/it]11/28/2024 06:01:24 - INFO - __main__ -   {"learning_rate": 1.4e-07, "loss": 0.14972817852501763, "step": 150700}
{"learning_rate": 1.4e-07, "loss": 0.14972817852501763, "step": 150700}
Inferencing: 708it [41:46,  3.52s/it]Inferencing: 709it [41:50,  3.53s/it]Inferencing: 710it [41:53,  3.53s/it]Inferencing: 711it [41:57,  3.51s/it]Inferencing: 712it [42:00,  3.51s/it]Inferencing: 713it [42:04,  3.51s/it]Inferencing: 714it [42:07,  3.52s/it]Inferencing: 715it [42:11,  3.55s/it]Inferencing: 716it [42:14,  3.57s/it]Inferencing: 717it [42:18,  3.58s/it]Inferencing: 718it [42:22,  3.55s/it]Inferencing: 719it [42:25,  3.57s/it]Inferencing: 720it [42:29,  3.54s/it]Inferencing: 721it [42:32,  3.56s/it]Inferencing: 722it [42:36,  3.54s/it]Inferencing: 723it [42:39,  3.53s/it]Inferencing: 724it [42:43,  3.55s/it]Inferencing: 725it [42:46,  3.56s/it]Inferencing: 726it [42:50,  3.56s/it]Inferencing: 727it [42:54,  3.56s/it]Inferencing: 728it [42:57,  3.53s/it]Inferencing: 729it [43:00,  3.51s/it]Inferencing: 730it [43:04,  3.50s/it]Inferencing: 731it [43:08,  3.54s/it]Inferencing: 732it [43:11,  3.53s/it]Inferencing: 733it [43:15,  3.55s/it]Inferencing: 734it [43:18,  3.53s/it]Inferencing: 735it [43:22,  3.55s/it]Inferencing: 736it [43:25,  3.57s/it]Inferencing: 737it [43:29,  3.58s/it]Inferencing: 738it [43:32,  3.55s/it]Inferencing: 739it [43:36,  3.54s/it]Inferencing: 740it [43:40,  3.54s/it]Inferencing: 741it [43:43,  3.52s/it]Inferencing: 742it [43:47,  3.53s/it]Inferencing: 743it [43:50,  3.52s/it]Inferencing: 744it [43:54,  3.53s/it]Inferencing: 745it [43:57,  3.56s/it]Inferencing: 746it [44:01,  3.54s/it]Inferencing: 747it [44:04,  3.55s/it]Inferencing: 748it [44:08,  3.53s/it]Inferencing: 749it [44:11,  3.52s/it]Inferencing: 750it [44:15,  3.54s/it]Inferencing: 751it [44:18,  3.55s/it]Inferencing: 752it [44:22,  3.57s/it]Inferencing: 753it [44:26,  3.58s/it]Inferencing: 754it [44:29,  3.59s/it]Inferencing: 755it [44:33,  3.57s/it]Inferencing: 756it [44:36,  3.54s/it]Inferencing: 757it [44:40,  3.55s/it]Inferencing: 758it [44:43,  3.55s/it]Inferencing: 759it [44:47,  3.57s/it]Inferencing: 760it [44:51,  3.58s/it]Inferencing: 761it [44:54,  3.59s/it]Inferencing: 762it [44:58,  3.58s/it]Inferencing: 763it [45:01,  3.55s/it]Inferencing: 764it [45:05,  3.52s/it]Inferencing: 765it [45:08,  3.51s/it]Inferencing: 766it [45:12,  3.50s/it]Inferencing: 767it [45:15,  3.49s/it]Inferencing: 768it [45:19,  3.52s/it]Inferencing: 769it [45:22,  3.54s/it]Inferencing: 770it [45:26,  3.56s/it]Inferencing: 771it [45:29,  3.55s/it]Inferencing: 772it [45:33,  3.54s/it]Inferencing: 773it [45:36,  3.53s/it]Inferencing: 774it [45:40,  3.54s/it]Inferencing: 775it [45:44,  3.53s/it]Inferencing: 776it [45:47,  3.54s/it]Inferencing: 777it [45:51,  3.52s/it]Inferencing: 778it [45:54,  3.51s/it]Inferencing: 779it [45:58,  3.50s/it]Inferencing: 780it [46:01,  3.49s/it]Inferencing: 781it [46:05,  3.51s/it]Inferencing: 782it [46:08,  3.53s/it]Inferencing: 783it [46:12,  3.56s/it]Inferencing: 784it [46:15,  3.54s/it]Inferencing: 785it [46:19,  3.55s/it]Inferencing: 786it [46:22,  3.55s/it]Inferencing: 787it [46:26,  3.54s/it]Inferencing: 788it [46:30,  3.56s/it]Inferencing: 789it [46:33,  3.56s/it]Inferencing: 790it [46:37,  3.53s/it]Inferencing: 791it [46:40,  3.54s/it]Inferencing: 792it [46:44,  3.53s/it]Inferencing: 793it [46:47,  3.52s/it]Inferencing: 794it [46:51,  3.55s/it]Inferencing: 795it [46:54,  3.56s/it]Inferencing: 796it [46:58,  3.57s/it]Inferencing: 797it [47:01,  3.56s/it]Inferencing: 798it [47:05,  3.56s/it]Inferencing: 799it [47:09,  3.58s/it]Inferencing: 800it [47:12,  3.58s/it]Inferencing: 801it [47:16,  3.55s/it]Inferencing: 802it [47:19,  3.56s/it]Inferencing: 803it [47:23,  3.58s/it]Inferencing: 804it [47:27,  3.59s/it]Inferencing: 805it [47:30,  3.57s/it]Inferencing: 806it [47:34,  3.58s/it]Inferencing: 807it [47:37,  3.56s/it]11/28/2024 06:07:18 - INFO - __main__ -   {"learning_rate": 1.6e-07, "loss": 0.19885195740895312, "step": 150800}
{"learning_rate": 1.6e-07, "loss": 0.19885195740895312, "step": 150800}
Inferencing: 808it [47:41,  3.55s/it]Inferencing: 809it [47:44,  3.56s/it]Inferencing: 810it [47:48,  3.55s/it]Inferencing: 811it [47:51,  3.57s/it]Inferencing: 812it [47:55,  3.58s/it]Inferencing: 813it [47:59,  3.57s/it]Inferencing: 814it [48:02,  3.58s/it]Inferencing: 815it [48:06,  3.59s/it]Inferencing: 816it [48:09,  3.60s/it]Inferencing: 817it [48:13,  3.60s/it]Inferencing: 818it [48:16,  3.57s/it]Inferencing: 819it [48:20,  3.58s/it]Inferencing: 820it [48:24,  3.59s/it]Inferencing: 821it [48:27,  3.56s/it]Inferencing: 822it [48:31,  3.56s/it]Inferencing: 823it [48:34,  3.57s/it]Inferencing: 824it [48:38,  3.58s/it]Inferencing: 825it [48:41,  3.56s/it]Inferencing: 826it [48:45,  3.55s/it]Inferencing: 827it [48:48,  3.53s/it]Inferencing: 828it [48:52,  3.53s/it]Inferencing: 829it [48:56,  3.53s/it]Inferencing: 830it [48:59,  3.52s/it]Inferencing: 831it [49:02,  3.51s/it]Inferencing: 832it [49:06,  3.51s/it]Inferencing: 833it [49:10,  3.50s/it]Inferencing: 834it [49:13,  3.53s/it]Inferencing: 835it [49:17,  3.51s/it]Inferencing: 836it [49:20,  3.51s/it]Inferencing: 837it [49:24,  3.54s/it]Inferencing: 838it [49:27,  3.52s/it]Inferencing: 839it [49:31,  3.55s/it]Inferencing: 840it [49:34,  3.55s/it]Inferencing: 841it [49:38,  3.54s/it]Inferencing: 842it [49:41,  3.55s/it]Inferencing: 843it [49:45,  3.53s/it]Inferencing: 844it [49:48,  3.52s/it]Inferencing: 845it [49:52,  3.53s/it]Inferencing: 846it [49:56,  3.56s/it]Inferencing: 847it [49:59,  3.54s/it]Inferencing: 848it [50:03,  3.54s/it]Inferencing: 849it [50:06,  3.53s/it]Inferencing: 850it [50:10,  3.55s/it]Inferencing: 851it [50:13,  3.55s/it]Inferencing: 852it [50:17,  3.55s/it]Inferencing: 853it [50:20,  3.52s/it]Inferencing: 854it [50:24,  3.54s/it]Inferencing: 855it [50:27,  3.56s/it]Inferencing: 856it [50:31,  3.57s/it]Inferencing: 857it [50:35,  3.56s/it]Inferencing: 858it [50:38,  3.55s/it]Inferencing: 859it [50:42,  3.55s/it]Inferencing: 860it [50:45,  3.56s/it]Inferencing: 861it [50:49,  3.49s/it]11/28/2024 06:10:30 - INFO - __main__ -   Finished iterating current dataset, begin reiterate
Inferencing: 862it [50:52,  3.52s/it]Inferencing: 863it [50:56,  3.51s/it]Inferencing: 864it [50:57,  2.98s/it]Inferencing: 864it [50:57,  3.54s/it]
merging embeddings
11/28/2024 06:10:39 - INFO - __main__ -   merging embeddings
Traceback (most recent call last):
  File "../drivers/run_ann_data_gen.py", line 1316, in <module>
    main()
  File "../drivers/run_ann_data_gen.py", line 1311, in main
    ann_data_gen(args)
  File "../drivers/run_ann_data_gen.py", line 1288, in ann_data_gen
    generate_new_ann(
  File "../drivers/run_ann_data_gen.py", line 561, in generate_new_ann
    passage_embedding, passage_embedding2id = StreamInferenceDoc(args, model, GetProcessingFn(
  File "../drivers/run_ann_data_gen.py", line 504, in StreamInferenceDoc
    full_embedding = barrier_array_merge(
  File "/work/pi_mserafini_umass_edu/hojae/vector_database/ANCE/drivers/../utils/util.py", line 104, in barrier_array_merge
    os.makedirs(args.output_dir)
  File "/home/hojaeson_umass_edu/hojae_workspace/miniconda3/envs/ance/lib/python3.8/os.py", line 213, in makedirs
    makedirs(head, exist_ok=exist_ok)
  File "/home/hojaeson_umass_edu/hojae_workspace/miniconda3/envs/ance/lib/python3.8/os.py", line 213, in makedirs
    makedirs(head, exist_ok=exist_ok)
  File "/home/hojaeson_umass_edu/hojae_workspace/miniconda3/envs/ance/lib/python3.8/os.py", line 213, in makedirs
    makedirs(head, exist_ok=exist_ok)
  File "/home/hojaeson_umass_edu/hojae_workspace/miniconda3/envs/ance/lib/python3.8/os.py", line 223, in makedirs
    mkdir(name, mode)
FileNotFoundError: [Errno 2] No such file or directory: '/home/hojaeson_umass_edu/hojae_workspace/project/ance'
WARNING:torch.distributed.elastic.multiprocessing.api:Sending process 3863625 closing signal SIGTERM
WARNING:torch.distributed.elastic.multiprocessing.api:Sending process 3863627 closing signal SIGTERM
WARNING:torch.distributed.elastic.multiprocessing.api:Sending process 3863629 closing signal SIGTERM
ERROR:torch.distributed.elastic.multiprocessing.api:failed (exitcode: 1) local_rank: 0 (pid: 3863623) of binary: /home/hojaeson_umass_edu/hojae_workspace/miniconda3/envs/ance/bin/python
Traceback (most recent call last):
  File "/home/hojaeson_umass_edu/hojae_workspace/miniconda3/envs/ance/lib/python3.8/runpy.py", line 194, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "/home/hojaeson_umass_edu/hojae_workspace/miniconda3/envs/ance/lib/python3.8/runpy.py", line 87, in _run_code
    exec(code, run_globals)
  File "/home/hojaeson_umass_edu/hojae_workspace/miniconda3/envs/ance/lib/python3.8/site-packages/torch/distributed/launch.py", line 193, in <module>
    main()
  File "/home/hojaeson_umass_edu/hojae_workspace/miniconda3/envs/ance/lib/python3.8/site-packages/torch/distributed/launch.py", line 189, in main
    launch(args)
  File "/home/hojaeson_umass_edu/hojae_workspace/miniconda3/envs/ance/lib/python3.8/site-packages/torch/distributed/launch.py", line 174, in launch
    run(args)
  File "/home/hojaeson_umass_edu/hojae_workspace/miniconda3/envs/ance/lib/python3.8/site-packages/torch/distributed/run.py", line 715, in run
    elastic_launch(
  File "/home/hojaeson_umass_edu/hojae_workspace/miniconda3/envs/ance/lib/python3.8/site-packages/torch/distributed/launcher/api.py", line 131, in __call__
    return launch_agent(self._config, self._entrypoint, list(args))
  File "/home/hojaeson_umass_edu/hojae_workspace/miniconda3/envs/ance/lib/python3.8/site-packages/torch/distributed/launcher/api.py", line 245, in launch_agent
    raise ChildFailedError(
torch.distributed.elastic.multiprocessing.errors.ChildFailedError: 
============================================================
../drivers/run_ann_data_gen.py FAILED
------------------------------------------------------------
Failures:
  <NO_OTHER_FAILURES>
------------------------------------------------------------
Root Cause (first observed failure):
[0]:
  time      : 2024-11-28_06:10:44
  host      : gpu008.unity.rc.umass.edu
  rank      : 0 (local_rank: 0)
  exitcode  : 1 (pid: 3863623)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
============================================================
sbatch_train_index-a40_subset_10_bottom_neg_only.sh finished
