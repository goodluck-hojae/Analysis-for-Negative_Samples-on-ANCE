Thu Nov 28 03:23:51 2024       
+-----------------------------------------------------------------------------------------+
| NVIDIA-SMI 550.90.07              Driver Version: 550.90.07      CUDA Version: 12.4     |
|-----------------------------------------+------------------------+----------------------+
| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |
| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |
|                                         |                        |               MIG M. |
|=========================================+========================+======================|
|   0  NVIDIA A100-SXM4-80GB          On  |   00000000:BD:00.0 Off |                    0 |
| N/A   31C    P0             64W /  500W |       1MiB /  81920MiB |      0%      Default |
|                                         |                        |             Disabled |
+-----------------------------------------+------------------------+----------------------+
|   1  NVIDIA A100-SXM4-80GB          On  |   00000000:CD:00.0 Off |                    0 |
| N/A   32C    P0             64W /  500W |       1MiB /  81920MiB |      0%      Default |
|                                         |                        |             Disabled |
+-----------------------------------------+------------------------+----------------------+
                                                                                         
+-----------------------------------------------------------------------------------------+
| Processes:                                                                              |
|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |
|        ID   ID                                                               Usage      |
|=========================================================================================|
|  No running processes found                                                             |
+-----------------------------------------------------------------------------------------+
sbatch_initial_train_subset_30.sh
Loading conda
python -m torch.distributed.launch --master_port=29501 --nproc_per_node=2 ../drivers/run_ann_data_gen.py --training_dir /home/hojaeson_umass_edu/hojae_workspace/project/ance/data/30/checkpoints_2_bottom_neg_only --init_model_dir /home/hojaeson_umass_edu/hojae_workspace/project/ance/warmup/checkpoint-150000 --model_type rdot_nll --output_dir /home/hojaeson_umass_edu/hojae_workspace/project/ance/data/30/ann_data_2_bottom_neg_only --cache_dir /home/hojaeson_umass_edu/hojae_workspace/project/ance/data/30/ann_data_2_bottom_neg_onlycache/ --data_dir /home/hojaeson_umass_edu/hojae_workspace/vector_database/ANCE/data/30/preprocessed_data --max_seq_length 512 --per_gpu_eval_batch_size 256 --topk_training 200 --negative_sample 20 --ann_chunk_factor 20 --bottom_neg true --bottom_only true
/home/hojaeson_umass_edu/hojae_workspace/miniconda3/envs/ance/lib/python3.8/site-packages/torch/distributed/launch.py:178: FutureWarning: The module torch.distributed.launch is deprecated
and will be removed in future. Use torchrun.
Note that --use_env is set by default in torchrun.
If your script expects `--local_rank` argument to be set, please
change it to read from `os.environ['LOCAL_RANK']` instead. See 
https://pytorch.org/docs/stable/distributed.html#launch-utility for 
further instructions

  warnings.warn(
WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
Process rank: 1, device: cuda:1, n_gpu: 1, distributed training: True
11/28/2024 03:24:00 - WARNING - __main__ -   Process rank: 1, device: cuda:1, n_gpu: 1, distributed training: True
Process rank: 0, device: cuda:0, n_gpu: 1, distributed training: True
11/28/2024 03:24:00 - WARNING - __main__ -   Process rank: 0, device: cuda:0, n_gpu: 1, distributed training: True
Traceback (most recent call last):
  File "../drivers/run_ann_data_gen.py", line 1316, in <module>
starting output number 0
11/28/2024 03:24:00 - INFO - __main__ -   starting output number 0
    main()
  File "../drivers/run_ann_data_gen.py", line 1311, in main
    ann_data_gen(args)
  File "../drivers/run_ann_data_gen.py", line 1268, in ann_data_gen
    training_query_positive_id, dev_positive_id = load_positive_ids(args)
  File "../drivers/run_ann_data_gen.py", line 361, in load_positive_ids
    with open(query_positive_id_path, 'r', encoding='utf8') as f:
FileNotFoundError: [Errno 2] No such file or directory: '/home/hojaeson_umass_edu/hojae_workspace/vector_database/ANCE/data/30/preprocessed_data/train-qrel.tsv'
Loading query_2_pos_docid
11/28/2024 03:24:00 - INFO - __main__ -   Loading query_2_pos_docid
Traceback (most recent call last):
  File "../drivers/run_ann_data_gen.py", line 1316, in <module>
    main()
  File "../drivers/run_ann_data_gen.py", line 1311, in main
    ann_data_gen(args)
  File "../drivers/run_ann_data_gen.py", line 1268, in ann_data_gen
    training_query_positive_id, dev_positive_id = load_positive_ids(args)
  File "../drivers/run_ann_data_gen.py", line 361, in load_positive_ids
    with open(query_positive_id_path, 'r', encoding='utf8') as f:
FileNotFoundError: [Errno 2] No such file or directory: '/home/hojaeson_umass_edu/hojae_workspace/vector_database/ANCE/data/30/preprocessed_data/train-qrel.tsv'
ERROR:torch.distributed.elastic.multiprocessing.api:failed (exitcode: 1) local_rank: 0 (pid: 1611654) of binary: /home/hojaeson_umass_edu/hojae_workspace/miniconda3/envs/ance/bin/python
Traceback (most recent call last):
  File "/home/hojaeson_umass_edu/hojae_workspace/miniconda3/envs/ance/lib/python3.8/runpy.py", line 194, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "/home/hojaeson_umass_edu/hojae_workspace/miniconda3/envs/ance/lib/python3.8/runpy.py", line 87, in _run_code
    exec(code, run_globals)
  File "/home/hojaeson_umass_edu/hojae_workspace/miniconda3/envs/ance/lib/python3.8/site-packages/torch/distributed/launch.py", line 193, in <module>
    main()
  File "/home/hojaeson_umass_edu/hojae_workspace/miniconda3/envs/ance/lib/python3.8/site-packages/torch/distributed/launch.py", line 189, in main
    launch(args)
  File "/home/hojaeson_umass_edu/hojae_workspace/miniconda3/envs/ance/lib/python3.8/site-packages/torch/distributed/launch.py", line 174, in launch
    run(args)
  File "/home/hojaeson_umass_edu/hojae_workspace/miniconda3/envs/ance/lib/python3.8/site-packages/torch/distributed/run.py", line 715, in run
    elastic_launch(
  File "/home/hojaeson_umass_edu/hojae_workspace/miniconda3/envs/ance/lib/python3.8/site-packages/torch/distributed/launcher/api.py", line 131, in __call__
    return launch_agent(self._config, self._entrypoint, list(args))
  File "/home/hojaeson_umass_edu/hojae_workspace/miniconda3/envs/ance/lib/python3.8/site-packages/torch/distributed/launcher/api.py", line 245, in launch_agent
    raise ChildFailedError(
torch.distributed.elastic.multiprocessing.errors.ChildFailedError: 
============================================================
../drivers/run_ann_data_gen.py FAILED
------------------------------------------------------------
Failures:
[1]:
  time      : 2024-11-28_03:24:06
  host      : gpu024.unity.rc.umass.edu
  rank      : 1 (local_rank: 1)
  exitcode  : 1 (pid: 1611655)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
------------------------------------------------------------
Root Cause (first observed failure):
[0]:
  time      : 2024-11-28_03:24:06
  host      : gpu024.unity.rc.umass.edu
  rank      : 0 (local_rank: 0)
  exitcode  : 1 (pid: 1611654)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
============================================================
python -m torch.distributed.launch --master_port=29501 --nproc_per_node=2 ../drivers/run_ann_data_gen.py --training_dir /home/hojaeson_umass_edu/hojae_workspace/project/ance/data/30/checkpoints_2_bottom_neg_only --init_model_dir /home/hojaeson_umass_edu/hojae_workspace/project/ance/warmup/checkpoint-150000 --model_type rdot_nll --output_dir /home/hojaeson_umass_edu/hojae_workspace/project/ance/data/30/ann_data_2_bottom_neg_only --cache_dir /home/hojaeson_umass_edu/hojae_workspace/project/ance/data/30/ann_data_2_bottom_neg_onlycache/ --data_dir /home/hojaeson_umass_edu/hojae_workspace/vector_database/ANCE/data/30/preprocessed_data --max_seq_length 512 --per_gpu_eval_batch_size 512 --topk_training 200 --negative_sample 20 --ann_chunk_factor 20 --bottom_neg true --bottom_only true
python -m torch.distributed.launch --nproc_per_node=2 ../drivers/run_ann.py --model_type rdot_nll --model_name_or_path /home/hojaeson_umass_edu/hojae_workspace/project/ance/warmup/checkpoint-150000 --task_name MSMarco --triplet --data_dir /home/hojaeson_umass_edu/hojae_workspace/vector_database/ANCE/data/30/preprocessed_data --ann_dir /home/hojaeson_umass_edu/hojae_workspace/vector_database/ANCE/data/30/ann_data_2_bottom_neg_only --max_seq_length 512 --per_gpu_train_batch_size=32 --gradient_accumulation_steps 8 --learning_rate 1e-6 --output_dir /home/hojaeson_umass_edu/hojae_workspace/vector_database/ANCE/data/30/checkpoints_2_bottom_neg_only --warmup_steps 5000 --logging_steps 300 --save_steps 2000 --optimizer lamb --single_warmup
/home/hojaeson_umass_edu/hojae_workspace/miniconda3/envs/ance/lib/python3.8/site-packages/torch/distributed/launch.py:178: FutureWarning: The module torch.distributed.launch is deprecated
and will be removed in future. Use torchrun.
Note that --use_env is set by default in torchrun.
If your script expects `--local_rank` argument to be set, please
change it to read from `os.environ['LOCAL_RANK']` instead. See 
https://pytorch.org/docs/stable/distributed.html#launch-utility for 
further instructions

  warnings.warn(
WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
/home/hojaeson_umass_edu/hojae_workspace/miniconda3/envs/ance/lib/python3.8/site-packages/torch/distributed/launch.py:178: FutureWarning: The module torch.distributed.launch is deprecated
and will be removed in future. Use torchrun.
Note that --use_env is set by default in torchrun.
If your script expects `--local_rank` argument to be set, please
change it to read from `os.environ['LOCAL_RANK']` instead. See 
https://pytorch.org/docs/stable/distributed.html#launch-utility for 
further instructions

  warnings.warn(
WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
Process rank: 0, device: cuda:0, n_gpu: 1, distributed training: True
11/28/2024 03:24:10 - WARNING - __main__ -   Process rank: 0, device: cuda:0, n_gpu: 1, distributed training: True
starting output number 0
11/28/2024 03:24:10 - INFO - __main__ -   starting output number 0
Loading query_2_pos_docid
11/28/2024 03:24:10 - INFO - __main__ -   Loading query_2_pos_docid
Traceback (most recent call last):
  File "../drivers/run_ann_data_gen.py", line 1316, in <module>
    main()
  File "../drivers/run_ann_data_gen.py", line 1311, in main
    11/28/2024 03:24:10 - WARNING - __main__ -   Process rank: 1, device: cuda:1, n_gpu: 1, distributed training: True, 16-bits training: False
ann_data_gen(args)
  File "../drivers/run_ann_data_gen.py", line 1268, in ann_data_gen
    training_query_positive_id, dev_positive_id = load_positive_ids(args)
  File "../drivers/run_ann_data_gen.py", line 361, in load_positive_ids
    with open(query_positive_id_path, 'r', encoding='utf8') as f:
FileNotFoundError: [Errno 2] No such file or directory: '/home/hojaeson_umass_edu/hojae_workspace/vector_database/ANCE/data/30/preprocessed_data/train-qrel.tsv'
11/28/2024 03:24:10 - WARNING - __main__ -   Process rank: 1, device: cuda:1, n_gpu: 1, distributed training: True
Process rank: 1, device: cuda:1, n_gpu: 1, distributed training: True
Traceback (most recent call last):
  File "../drivers/run_ann_data_gen.py", line 1316, in <module>
    main()
  File "../drivers/run_ann_data_gen.py", line 1311, in main
    ann_data_gen(args)
  File "../drivers/run_ann_data_gen.py", line 1268, in ann_data_gen
    training_query_positive_id, dev_positive_id = load_positive_ids(args)
  File "../drivers/run_ann_data_gen.py", line 361, in load_positive_ids
    with open(query_positive_id_path, 'r', encoding='utf8') as f:
FileNotFoundError: [Errno 2] No such file or directory: '/home/hojaeson_umass_edu/hojae_workspace/vector_database/ANCE/data/30/preprocessed_data/train-qrel.tsv'
11/28/2024 03:24:10 - WARNING - __main__ -   Process rank: 0, device: cuda:0, n_gpu: 1, distributed training: True, 16-bits training: False
11/28/2024 03:24:10 - INFO - transformers.configuration_utils -   loading configuration file /home/hojaeson_umass_edu/hojae_workspace/project/ance/warmup/checkpoint-150000/config.json
11/28/2024 03:24:10 - INFO - transformers.configuration_utils -   Model config {
  "architectures": [
    "RobertaForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "bos_token_id": 0,
  "eos_token_id": 2,
  "finetuning_task": "msmarco",
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1"
  },
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "is_decoder": false,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1
  },
  "layer_norm_eps": 1e-05,
  "max_position_embeddings": 514,
  "model_type": "roberta",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "num_labels": 2,
  "output_attentions": false,
  "output_hidden_states": false,
  "output_past": true,
  "pad_token_id": 1,
  "pruned_heads": {},
  "torchscript": false,
  "type_vocab_size": 1,
  "use_bfloat16": false,
  "vocab_size": 50265
}

11/28/2024 03:24:10 - INFO - transformers.tokenization_utils -   Model name '/home/hojaeson_umass_edu/hojae_workspace/project/ance/warmup/checkpoint-150000' not found in model shortcut name list (roberta-base, roberta-large, roberta-large-mnli, distilroberta-base, roberta-base-openai-detector, roberta-large-openai-detector). Assuming '/home/hojaeson_umass_edu/hojae_workspace/project/ance/warmup/checkpoint-150000' is a path or url to a directory containing tokenizer files.
11/28/2024 03:24:10 - INFO - transformers.tokenization_utils -   loading file /home/hojaeson_umass_edu/hojae_workspace/project/ance/warmup/checkpoint-150000/vocab.json
11/28/2024 03:24:10 - INFO - transformers.tokenization_utils -   loading file /home/hojaeson_umass_edu/hojae_workspace/project/ance/warmup/checkpoint-150000/merges.txt
11/28/2024 03:24:10 - INFO - transformers.tokenization_utils -   loading file /home/hojaeson_umass_edu/hojae_workspace/project/ance/warmup/checkpoint-150000/added_tokens.json
11/28/2024 03:24:10 - INFO - transformers.tokenization_utils -   loading file /home/hojaeson_umass_edu/hojae_workspace/project/ance/warmup/checkpoint-150000/special_tokens_map.json
11/28/2024 03:24:10 - INFO - transformers.tokenization_utils -   loading file /home/hojaeson_umass_edu/hojae_workspace/project/ance/warmup/checkpoint-150000/tokenizer_config.json
11/28/2024 03:24:10 - INFO - transformers.modeling_utils -   loading weights file /home/hojaeson_umass_edu/hojae_workspace/project/ance/warmup/checkpoint-150000/pytorch_model.bin
Using mean: False
ERROR:torch.distributed.elastic.multiprocessing.api:failed (exitcode: 1) local_rank: 0 (pid: 1611821) of binary: /home/hojaeson_umass_edu/hojae_workspace/miniconda3/envs/ance/bin/python
Traceback (most recent call last):
  File "/home/hojaeson_umass_edu/hojae_workspace/miniconda3/envs/ance/lib/python3.8/runpy.py", line 194, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "/home/hojaeson_umass_edu/hojae_workspace/miniconda3/envs/ance/lib/python3.8/runpy.py", line 87, in _run_code
    exec(code, run_globals)
  File "/home/hojaeson_umass_edu/hojae_workspace/miniconda3/envs/ance/lib/python3.8/site-packages/torch/distributed/launch.py", line 193, in <module>
    main()
  File "/home/hojaeson_umass_edu/hojae_workspace/miniconda3/envs/ance/lib/python3.8/site-packages/torch/distributed/launch.py", line 189, in main
    launch(args)
  File "/home/hojaeson_umass_edu/hojae_workspace/miniconda3/envs/ance/lib/python3.8/site-packages/torch/distributed/launch.py", line 174, in launch
    run(args)
  File "/home/hojaeson_umass_edu/hojae_workspace/miniconda3/envs/ance/lib/python3.8/site-packages/torch/distributed/run.py", line 715, in run
    elastic_launch(
  File "/home/hojaeson_umass_edu/hojae_workspace/miniconda3/envs/ance/lib/python3.8/site-packages/torch/distributed/launcher/api.py", line 131, in __call__
    return launch_agent(self._config, self._entrypoint, list(args))
  File "/home/hojaeson_umass_edu/hojae_workspace/miniconda3/envs/ance/lib/python3.8/site-packages/torch/distributed/launcher/api.py", line 245, in launch_agent
    raise ChildFailedError(
torch.distributed.elastic.multiprocessing.errors.ChildFailedError: 
============================================================
../drivers/run_ann_data_gen.py FAILED
------------------------------------------------------------
Failures:
[1]:
  time      : 2024-11-28_03:24:12
  host      : gpu024.unity.rc.umass.edu
  rank      : 1 (local_rank: 1)
  exitcode  : 1 (pid: 1611823)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
------------------------------------------------------------
Root Cause (first observed failure):
[0]:
  time      : 2024-11-28_03:24:12
  host      : gpu024.unity.rc.umass.edu
  rank      : 0 (local_rank: 0)
  exitcode  : 1 (pid: 1611821)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
============================================================
commands/sbatch_initial_train_subset_30_neg_only.sh
